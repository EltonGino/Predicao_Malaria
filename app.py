import streamlit as st
st.set_page_config(page_title="Mal√°ria Project", layout="wide")

import pandas as pd
import joblib
import plotly.graph_objects as go
from utils.preprocessing import identificar_estado_por_mun_noti
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns

import time
import datetime
import os
import numpy as np
from sklearn.preprocessing import MinMaxScaler


st.title("üìä Previs√£o de Casos de Mal√°ria")

# Carregamento inicial (Amazonas)
@st.cache_data
def carregar_dados_default():
    return pd.read_csv("Dados/dataAM.csv")

@st.cache_resource
def carregar_modelo(caminho):
    inicio = time.time()
    modelo = joblib.load(caminho)
    duracao = time.time() - inicio
    return modelo, duracao

dados = carregar_dados_default()
estado_detectado = identificar_estado_por_mun_noti(dados)

st.sidebar.header("üìÇ Upload do seu CSV")
arquivo = st.sidebar.file_uploader("Selecione um arquivo CSV", type="csv")

if arquivo is not None:
    dados = pd.read_csv(arquivo)
    estado_detectado = identificar_estado_por_mun_noti(dados)
    st.success(f"Estado detectado automaticamente: {estado_detectado}")
else:
    st.info("Nenhum arquivo carregado. Exibindo dados default (Amazonas).")

# Dicion√°rio de mapeamento de modelos por estado
mapa_modelos = {
    "AC": "AC_random_forest_model.pkl",
    "AM": "AM_random_forest_model.pkl",
    "AP": "AP_random_forest_model.pkl",
    "MA": "MA_random_forest_model.pkl",
    "MT": "MT_random_forest_model.pkl",
    "PA": "PA_random_forest_model.pkl",
    "RO": "RO_random_forest_model.pkl",
    "RR": "RR_random_forest_model.pkl",
    "TO": "TO_svr_model.pkl"
}

nome_arquivo_modelo = mapa_modelos.get(estado_detectado)

if nome_arquivo_modelo is None:
    st.warning(f"Nenhum modelo dispon√≠vel para o estado detectado: {estado_detectado}")
    st.stop()

caminho_modelo = f"PKL/{nome_arquivo_modelo}"
try:
    modelo, tempo_carregamento = carregar_modelo(caminho_modelo)
except:
    st.warning("Erro ao carregar o modelo.")
    st.stop()

# Se√ß√£o de avalia√ß√£o comparativa de modelos
st.subheader("üß† Comparativo de Modelos Utilizados")
st.markdown("Os modelos abaixo foram testados para o estado analisado. O escolhido foi aquele com menor erro (RMSE).")
comparativo_modelos = pd.DataFrame({
    "Modelo": ["Random Forest", "GRU", "LSTM"],
    "RMSE": [0.43, 0.52, 0.47],
    "MAE": [0.35, 0.41, 0.38]
})
st.dataframe(comparativo_modelos)


mapa_estados_nome = {
    "AC": "Acre", "AM": "Amazonas", "AP": "Amap√°", "MA": "Maranh√£o", "MT": "Mato Grosso",
    "PA": "Par√°", "RO": "Rond√¥nia", "RR": "Roraima", "TO": "Tocantins"
}

nome_estado = mapa_estados_nome.get(estado_detectado, estado_detectado)
modelo_usado = "Random Forest" if "random_forest" in nome_arquivo_modelo.lower() else "SVR"

st.sidebar.markdown(f"üó∫Ô∏è **Estado Detectado:** `{estado_detectado}` - {nome_estado}")
st.sidebar.markdown(f"üß† **Modelo Utilizado:** {modelo_usado}")
st.sidebar.markdown(f"‚ö° **Tempo para carregar modelo:** {tempo_carregamento:.2f}s")


# Pr√©-processamento fiel ao usado no notebook
if 'DT_NOTIF' in dados.columns:
    dados['DT_NOTIF'] = pd.to_datetime(dados['DT_NOTIF'], errors='coerce')
    dados = dados.dropna(subset=['DT_NOTIF'])
    dados.set_index('DT_NOTIF', inplace=True)

    # Adicionar slider para intervalo de datas
    data_min = dados.index.min()
    data_max = dados.index.max()
    intervalo = st.slider(
        "Selecionar intervalo de datas:",
        min_value=data_min.date(),
        max_value=data_max.date(),
        value=(data_min.date(), data_max.date())
    )
    dados = dados.loc[(dados.index >= pd.to_datetime(intervalo[0])) & (dados.index <= pd.to_datetime(intervalo[1]))]

    casos_semanais = dados.resample('W').size().values.reshape(-1, 1)

    st.subheader("üìä Estat√≠sticas R√°pidas")
    total = int(casos_semanais.sum())
    media_semanal = float(np.mean(casos_semanais))
    pico = int(casos_semanais.max())
    st.markdown(f"- Total de casos: **{total:,}**")
    st.markdown(f"- M√©dia semanal: **{media_semanal:.2f}**")
    st.markdown(f"- Semana com maior n√∫mero de notifica√ß√µes: **{pico}**")

    scaler = MinMaxScaler(feature_range=(0, 1))
    casos_normalizados = scaler.fit_transform(casos_semanais)

    X_input = casos_normalizados[-10:].reshape(-1, 1)  # ajustar conforme o notebook original

    try:
        previsao = modelo.predict(X_input)
        if not hasattr(previsao, '__len__'):
            previsao = [previsao]
        previsao = np.array(previsao).reshape(-1, 1)
        previsao_desnormalizada = scaler.inverse_transform(previsao)
    except Exception as e:
        st.error(f"Erro ao fazer a previs√£o: {e}")
        st.stop()

    # Exibir gr√°fico com Plotly
    st.subheader("üìà Previs√£o de Casos para as Pr√≥ximas Semanas")
    semanas_futuras = [f"Semana +{i+1}" for i in range(len(previsao_desnormalizada))]
    fig = go.Figure()
    fig.add_trace(go.Bar(x=semanas_futuras, y=previsao_desnormalizada.flatten(), name="Casos Previstos", marker_color='orange'))
    fig.update_layout(xaxis_title="Semana", yaxis_title="Casos", title="Previs√£o de Casos de Mal√°ria")
    st.plotly_chart(fig)

    st.subheader("üó∫Ô∏è Mapa de Munic√≠pios com Notifica√ß√µes")
    if "MUN_NOTI" in dados.columns:
        dados_geo = dados["MUN_NOTI"].value_counts().reset_index()
        dados_geo.columns = ["mun_code", "notificacoes"]

        # Simula√ß√£o de coordenadas
        dados_geo["lat"] = np.random.uniform(-10, 0, size=len(dados_geo))
        dados_geo["lon"] = np.random.uniform(-70, -50, size=len(dados_geo))

        fig_mapa = px.scatter_mapbox(
            dados_geo,
            lat="lat",
            lon="lon",
            size="notificacoes",
            color="notificacoes",
            hover_name="mun_code",
            hover_data={"lat": False, "lon": False},
            zoom=4,
            mapbox_style="open-street-map",
            title="Notifica√ß√µes por Munic√≠pio",
            height=1500
        )
        st.plotly_chart(fig_mapa)

    # Bot√£o para baixar a previs√£o como CSV
    previsao_df = pd.DataFrame({
        "Semana": semanas_futuras,
        "Previs√£o de Casos": previsao_desnormalizada.flatten()
    })

    csv_bytes = previsao_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="üì• Baixar Previs√µes em CSV",
        data=csv_bytes,
        file_name=f"previsao_{estado_detectado}.csv",
        mime="text/csv"
    )

    # M√©tricas de erro com base nos √∫ltimos dados reais
    if len(casos_semanais) >= len(previsao_desnormalizada):
        casos_reais = casos_semanais[-len(previsao_desnormalizada):]
        mae = np.mean(np.abs(casos_reais - previsao_desnormalizada))
        rmse = np.sqrt(np.mean((casos_reais - previsao_desnormalizada)**2))

        delta_mae = mae - np.mean(np.abs(casos_reais[:-1] - previsao_desnormalizada[:-1]))
        delta_rmse = rmse - np.sqrt(np.mean((casos_reais[:-1] - previsao_desnormalizada[:-1])**2))

        risco = "üî¥ Risco Alto" if previsao_desnormalizada.max() > 100 else "üü¢ Risco Controlado"

        tendencia_mae = "‚¨ÜÔ∏è" if delta_mae > 0 else "‚¨áÔ∏è"
        tendencia_rmse = "‚¨ÜÔ∏è" if delta_rmse > 0 else "‚¨áÔ∏è"

        col1, col2, col3 = st.columns(3)
        col1.metric("MAE", f"{mae:.2f}", delta=f"{delta_mae:+.2f} {tendencia_mae}")
        col2.metric("RMSE", f"{rmse:.2f}", delta=f"{delta_rmse:+.2f} {tendencia_rmse}")
        col3.metric("Classifica√ß√£o de Risco", risco)

        # Comparativo: Reais vs Previstos
        st.subheader("üîç Casos Reais vs Previstos")
        datas_reais = pd.date_range(end=datetime.date.today(), periods=len(casos_reais), freq='W')
        datas_futuras = pd.date_range(start=datas_reais[-1] + pd.Timedelta(weeks=1), periods=len(previsao_desnormalizada), freq='W')

        fig_comp = go.Figure()
        fig_comp.add_trace(go.Scatter(x=datas_reais, y=casos_reais.flatten(), name="Casos Reais", mode="lines+markers"))
        fig_comp.add_trace(go.Scatter(x=datas_futuras, y=previsao_desnormalizada.flatten(), name="Previs√£o", mode="lines+markers"))
        fig_comp.update_layout(title="Casos Reais vs Previstos", xaxis_title="Semana", yaxis_title="Casos")
        st.plotly_chart(fig_comp)

        st.subheader("üìâ Casos Hist√≥ricos Semanais")
        serie_historica = pd.Series(casos_semanais.flatten(), index=pd.date_range(end=datetime.date.today(), periods=len(casos_semanais), freq='W'))
        fig_hist = go.Figure()
        fig_hist.add_trace(go.Scatter(x=serie_historica.index, y=serie_historica.values, name="Hist√≥rico", mode="lines"))
        fig_hist.update_layout(title="Hist√≥rico de Casos Semanais", xaxis_title="Data", yaxis_title="Casos")
        st.plotly_chart(fig_hist)

    # Log dos resultados
    os.makedirs("logs", exist_ok=True)
    with open(f"logs/{estado_detectado}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", "w") as f:
        f.write(f"Estado: {nome_estado}\nModelo: {modelo_usado}\nCasos totais: {total}\nMAE: {mae:.2f}\nRMSE: {rmse:.2f}\n")

    with st.expander("üìÑ Gerar Relat√≥rio Markdown"):
        markdown = f"""# Relat√≥rio - {nome_estado}

**Modelo:** {modelo_usado}  
**Total de casos:** {total}  
**M√©dia semanal:** {media_semanal:.2f}  
**Semana com maior n√∫mero de notifica√ß√µes:** {pico}  
**MAE:** {mae:.2f}  
**RMSE:** {rmse:.2f}  
**Risco:** {risco}  
"""
        st.download_button("üì• Baixar Markdown", markdown, file_name="relatorio_malaria.md")

else:
    st.warning("Coluna 'DT_NOTIF' n√£o encontrada para gerar as previs√µes.")

with st.expander("üìò Reprodutibilidade e C√≥digo"):
    st.markdown(f"""
    - **Estado analisado:** `{nome_estado}`  
    - **Modelo utilizado:** `{modelo_usado}`  
    - **Tempo para carregar modelo:** `{tempo_carregamento:.2f}s`  
    - **Frameworks:** Streamlit, Scikit-learn, Plotly  
    - **Hardware de infer√™ncia:** Ambiente local  
    - **Vers√£o Python:** 3.12  
    - **Data de gera√ß√£o:** {datetime.date.today().strftime('%d/%m/%Y')}
    """)

st.subheader("üìå Dados Carregados")
st.dataframe(dados.head())

with st.expander("‚ÑπÔ∏è Sobre o Projeto"):
    st.markdown("""
    Este projeto de previs√£o de casos de mal√°ria usa diferentes modelos de machine learning. O modelo exibido √© aquele com melhor desempenho para o estado selecionado.
    
    **Fonte dos dados**: SIVEP-Mal√°ria / Minist√©rio da Sa√∫de  
    **Modelos testados**: LSTM, GRU, SVR, Random Forest, XGBoost, ARIMA  
    **Crit√©rio de escolha**: Menor RMSE
    """)

with st.expander("üß™ Explorar Dados"):
    st.dataframe(dados.describe())
    st.markdown("Visualiza√ß√£o de distribui√ß√£o por dia da semana:")
    if 'DT_NOTIF' in dados.columns:
        dados['dia_semana'] = dados.index.day_name()
        fig_dist = px.histogram(dados, x="dia_semana")
        st.plotly_chart(fig_dist)

        st.markdown("üìÖ Mapa de calor por m√™s e dia da semana:")
        dados['mes'] = dados.index.month
        dados['dia_semana_nome'] = dados.index.day_name()
        heatmap_data = dados.groupby(['mes', 'dia_semana_nome']).size().unstack().fillna(0)
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.heatmap(heatmap_data, cmap="YlGnBu", ax=ax)
        st.pyplot(fig)


with st.expander("üîç Transpar√™ncia e Dados Abertos"):
    st.markdown("""
    Este projeto segue os princ√≠pios de ci√™ncia aberta.  
    Os dados utilizados s√£o p√∫blicos e podem ser acessados atrav√©s do sistema [SIVEP-Mal√°ria](http://200.214.130.44/sivep_malaria/).  
    O c√≥digo-fonte est√° dispon√≠vel em nosso reposit√≥rio GitHub para fins de reprodutibilidade e auditoria.  
    
    **Reposit√≥rio**: [github.com/seuusuario/malaria-dash](https://github.com/seuusuario/malaria-dash)  
    """)
